{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "os.chdir(os.path.dirname(os.getcwd(abdull)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import glob\n",
    "import time\n",
    "import argparse\n",
    "import json\n",
    "from easydict import EasyDict\n",
    "import copy\n",
    "import pprint\n",
    "from collections import namedtuple\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', None)\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchcontrib\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import fastai\n",
    "from fastai.basic_data import DataBunch\n",
    "# from fastai.vision import Learner\n",
    "from modules.blend_data_augmentation import Learner\n",
    "from fastai.distributed import setup_distrib, num_distrib\n",
    "\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "\n",
    "import models.model_list as model_list\n",
    "from modules.adabound import AdaBound\n",
    "from modules.ranger913A import Ranger\n",
    "from modules.train_annealing import fit_with_annealing\n",
    "import modules.swa as swa\n",
    "from utils.dataloader import get_data_loaders, get_fastai_data_bunch\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "from utils.losses import MosLoss\n",
    "from utils.metrics import accuracy, macro_f1, genus_accuracy, species_accuracy,\\\n",
    "                            genus_f1_score, species_f1_score\n",
    "from utils.misc import log_metrics, cosine_annealing_lr\n",
    "from utils.callbacks import SaveBestModel, WandbCallback\n",
    "from utils.vis_utils import plttensor\n",
    "\n",
    "# from utils.logger import Logger as TfLogger\n",
    "# from tensorboardX import SummaryWriter\n",
    "import wandb\n",
    "\n",
    "from configs.config import config\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "if not os.path.exists('./configs/old_configs/'+config.exp_name):\n",
    "    os.makedirs('./configs/old_configs/'+config.exp_name)\n",
    "shutil.copy2('./configs/config.py', './configs/old_configs/{}/config.py'\n",
    "                    .format(config.exp_name))\n",
    "\n",
    "if not os.path.exists('./model_weights/'+config.exp_name):\n",
    "    os.makedirs('./model_weights/'+config.exp_name)\n",
    "if not os.path.exists('./subm/'+config.exp_name):\n",
    "    os.makedirs('./subm/'+config.exp_name) \n",
    "    \n",
    "args = EasyDict()\n",
    "args.dev_mode = False\n",
    "args.resume = False\n",
    "args.latest = False\n",
    "args.realtime = False\n",
    "\n",
    "pprint.pprint(config)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_map(df):\n",
    "    class_map = {}\n",
    "    for i in range(len(df)):\n",
    "        class_map[df.loc[i, 'Species']] = df.loc[i, 'Species_Name']\n",
    "    return class_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm = get_class_map(pd.read_csv(config.DATA_CSV_PATH))\n",
    "for i in range(len(cm)):\n",
    "    print(i, \": \", cm[i])\n",
    "print(len(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = [config.exp_name, config.model_name]\n",
    "MODEL_CKPT = os.path.abspath('./model_weights/{}/best_{}.pth'.format(*model_params))\n",
    "\n",
    "Net = getattr(model_list, config.model_name)\n",
    "\n",
    "net = Net(config=config)\n",
    "\n",
    "gpu = setup_distrib(config.gpu)\n",
    "opt = config.optimizer\n",
    "mom = config.mom\n",
    "alpha = config.alpha\n",
    "eps = config.eps\n",
    "\n",
    "if   opt=='adam': opt_func = partial(optim.Adam, betas=(mom,alpha), eps=eps)\n",
    "elif opt=='adamw': opt_func = partial(optim.AdamW, betas=(mom,alpha), eps=eps)\n",
    "elif opt=='radam': opt_func = partial(RAdam, betas=(mom,alpha), eps=eps)\n",
    "elif opt=='novograd': opt_func = partial(Novograd, betas=(mom,alpha), eps=eps)\n",
    "elif opt=='rms': opt_func = partial(optim.RMSprop, alpha=alpha, eps=eps)\n",
    "elif opt=='sgd': opt_func = partial(optim.SGD, momentum=mom)\n",
    "elif opt=='rangervar': opt_func = partial(RangerVar,  betas=(mom,alpha), eps=eps)\n",
    "elif opt=='ranger': opt_func = partial(Ranger,  betas=(mom,alpha), eps=eps)\n",
    "elif opt=='ralamb': opt_func = partial(Ralamb,  betas=(mom,alpha), eps=eps)\n",
    "elif opt=='over9000': opt_func = partial(Over9000,  k=12, betas=(mom,alpha), eps=eps)\n",
    "elif opt=='lookahead': opt_func = partial(LookaheadAdam, betas=(mom,alpha), eps=eps)\n",
    "elif opt=='Adams': opt_func=partial(Adams)\n",
    "elif opt=='rangernovo': opt_func=partial(RangerNovo)\n",
    "elif opt=='rangerlars': opt_func=partial(RangerLars)\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Optimizer not recognized\")\n",
    "        \n",
    "train_ds, valid_ds = get_data_loaders(config, get_dataset=True, one_hot_labels=config.one_hot_labels)\n",
    "print(\"Train dataset size = {}\".format(len(train_ds)))\n",
    "data = DataBunch.create(train_ds, valid_ds, bs=config.batch_size,\n",
    "                         num_workers=config.num_workers)\n",
    "loss = MosLoss(config=config)\n",
    "\n",
    "freeze_bn = False\n",
    "save_imgs = False\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "valid_f1s = []\n",
    "lr_hist = []\n",
    "\n",
    "# callback_fns=[WandbCallback] if (config.wandb and not get_learn) else []\n",
    "\n",
    "print('Training ...')\n",
    "print('Saving to ', MODEL_CKPT)\n",
    "metrics = [partial(accuracy, one_hot_labels=config.one_hot_labels), partial(macro_f1, one_hot_labels=config.one_hot_labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = (Learner(data, net, wd=config.weight_decay, opt_func=opt_func,\n",
    "         metrics=metrics,\n",
    "         bn_wd=False, true_wd=True,\n",
    "         loss_func = loss,\n",
    "         # loss_func = LabelSmoothingCrossEntropy(),\n",
    "#          callback_fns=callback_fns,\n",
    "         model_dir=MODEL_CKPT)\n",
    "        )\n",
    "\n",
    "if gpu is None: learn.to_parallel()\n",
    "elif num_distrib()>1: learn.to_distributed(gpu)\n",
    "\n",
    "best_save_cb = SaveBestModel(learn, config=config)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(config.epochs, config.lr, div_factor=10, pct_start=0.3, callbacks=[best_save_cb])        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run test.py --metric acc --tta 1 --config 'configs/old_configs/paper_redo/fold4/config.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run test.py --metric acc --tta 1 --features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from configs.old_configs.paper_redo.fold4.config import config\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', None)\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "subm = pd.read_csv('./subm/{}/best_acc.csv'.format(config.exp_name))\n",
    "(subm['Species'] == subm['SpeciesPred']).sum()/len(subm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pretty_blue_confusion_matrix(y_true, y_pred, classes,\n",
    "                                      normalize=False,\n",
    "                                      title=None,\n",
    "                                      cmap=plt.cm.Blues,\n",
    "                                      savepath=None,\n",
    "                                      figsize=(24,24)):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    precisions = np.diag(cm) / np.sum(cm, axis = 0)\n",
    "    recalls = np.diag(cm) / np.sum(cm, axis = 1)\n",
    "    print(\"Precision: \", np.round(precisions, 4))\n",
    "    print(\"Recall: \", np.round(recalls, 4))\n",
    "\n",
    "    # Only use the labels that appear in the data\n",
    "#     classes = classes[unique_labels(y_true, y_pred)]\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print(\"Confusion matrix\")\n",
    "\n",
    "    # print(cm)\n",
    "    save_df = pd.DataFrame(data=cm, columns=classes)\n",
    "    save_df.index = classes\n",
    "    if savepath is not None:\n",
    "        save_df.to_csv(savepath.replace(savepath.split('/')[-1],'confusion.csv'), index=True)\n",
    "    else:\n",
    "        save_df.to_csv('./subm/confusion.csv', index=True)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "    plt.xticks(fontsize=round(figsize[0]*.5))\n",
    "    plt.yticks(fontsize=round(figsize[0]*.5))\n",
    "    ax.set_xlabel('True label',fontsize=round(figsize[0]*.75))\n",
    "    ax.set_ylabel('Predicted label',fontsize=round(figsize[0]*.75))\n",
    "    plt.title(label=title,fontsize=round(figsize[0]))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "\n",
    "    # ax.tick_params(direction='out', length=6, width=2, colors='r',\n",
    "    #            grid_color='r', grid_alpha=0.5)\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "    # plt.tight_layout()\n",
    "    plt.gcf().subplots_adjust(bottom=0.25)\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            val = cm[i, j]\n",
    "            if math.isnan(val):\n",
    "                val = 0.0\n",
    "            ax.text(j, i, format(val, fmt),\n",
    "                    ha=\"center\", va=\"center\", size=round(figsize[0]*.5),\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    if savepath is not None:\n",
    "        fig.savefig(savepath)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from post_plots import plot_pretty_blue_confusion_matrix \n",
    "plot_pretty_blue_confusion_matrix(subm['Species'], subm['SpeciesPred'],\n",
    "                      np.array([i[1] for i in config.class_map[:config.num_species.sum()]]), normalize=True,\n",
    "                      savepath='./subm/{}/confusion_matrix.png'.format(config.exp_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python post_plots.py --infile ./subm/run68/best_acc.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Features & Probabilities for full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run test.py --full_df --metric acc --tta 1 --features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run test.py --full_df --metric acc --tta 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model2",
   "language": "python",
   "name": "model2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
